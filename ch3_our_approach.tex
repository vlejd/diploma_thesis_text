\chapter{Our approach}

In this chapter we describe our motivations, the design of our approach and some implementation details.

\section{Goals and motivation}

    In LSA, the SVD will inevitably throw away some information. 
    This is due the dimensionality reduction that it performs.
    The problem is, that this information may be vital to the classification task. 
    It is clear, that we need to introduce some form of supervision, that happens before the SVD.
    
    This is done to some extend by the supervised word weights described in section \ref{sec:supervised:weights}. 
    However, we consider this supervision rather weak, as it only computes simple statistics over words and labels.
    
    We would like to incorporate some form of direct supervision, that can be affected by the actual performance of the discriminator.
    We think it can be achieved by training our own word weighting scheme. 
    
    Our goals are:
    \begin{itemize}
        \item Propose a novel approach for learning task-specific word weights.
        \item Experimentally evaluate the performance of the new approach.
        \item Compare the new approach with other (commonly used) weighting schemes. 
        \item Extract new insights about the dataset.
    \end{itemize}
    
    As a side goal, we would like to introduce only a minimal amount of new hyperparameters
    as they may cause a ``false improvement'' of our approach over the baseline.
    In the best case scenario, we want our approach to be at least slightly interpretable.
    It would be nice, if it could produce some insight to the dataset.
    
    Because of the supervised weights, we know that supervision helps. 
    The only problem is, how to achieve it. 
    Here we take the inspiration from neural networks, and the insight that we can easily optimize parameters of rather complex system, as long as each part of this system is differentiable. 

\section{Design}

    First recall how does the original LSA works in context of document classification.
    We start with a sentence $s_i$. We represent it as a bag of words vector $d_i'$. 
    We transform it with some weighting scheme into a term vector $d_i$.
    Afterwards we compute the lower dimensional embedding of the document $v_i = d_i U$. 
    
    Finally we use these embeddings $v_i$ as features $x_i$ that are an input to the classifier (logistic regression, neural network, SVM).
    This classifier predicts some labels $\hat{y}$ that can be compared to
    the true labels $y$.
    
    Our contribution is to introduce another layer of reweighting. 
    Instead of using the term vector $d_i$, we introduce weights $w'$ and use reweighted vector $d_i \circ w'$.
    Recall, that $\circ$ means Hadamard product (pointwise multiplication).
    This is equivalent to multiplying the vector $d_i$ by diagonal matrix with diagonal $w'$.
    
    Further we do not perform the SVD decomposition on the matrix $M$, 
    but on the reweighted version $M \circ w'$. 
    Here we employ a few conventions from popular linear algebra library NumPy \cite{oliphant2006guide}, 
    where such operation is automatically broadcasted through the matrix.
    
    We initialize the $w'$ to be a vector of ones. 
    This effectively does not change the matrix at first.
    Now we are interested, in finding the best $w'$. 
    
    Recall, that for fixed decomposition $M\circ w'= U\Sigma V^T$ and some classifier $C$ (like a neural network),
    we compute $\hat{y} = C(M \circ w' U)$.
    We want to optimize $w'$ to minimize some error $E_y(\hat{y})$.
    The only question is, how to do it.
    
    The natural choice is to employ the gradient descent algorithm. 
    However to use it, we need to be able to compute the gradient of error with regards to the weights $\frac{\partial E_y(\hat{y})}{\partial w'}$.
    
    \subsection{Gradient computation}
    
    To compute the gradient efficiently, we recall the backpropagation trick mentioned in section \ref{sec:backprop}.
    We can compute the derivation $\frac{\partial E_y(\hat{y})}{\partial w'}$ thanks to the chain rule
    
    \begin{align}
    \frac{\partial E_y(\hat{y})}{\partial w'} = \frac{\partial E_y(\hat{y})}{\partial \hat{y}} \frac{\partial c(x)}{\partial x} \frac{\partial x}{\partial d}
    \end{align}
    
    To compute the derivation $\frac{\partial E_y(\hat{y})}{\partial w'} = \frac{\partial E_y(\hat{y})}{\partial \hat{y}} \frac{\partial C(x)}{\partial x} \frac{\partial x}{\partial d}$ we realize,
    that each part of this expression is easy to calculate.
    
    The first part of this expression is a function dependent on the chosen error function. 
    For L2 error we get 
    $\frac{\partial E_y(\hat{y})}{\partial \hat{y}} = \frac{\partial \frac{1}{2}(\hat{y}-y)^2}{\partial \hat{y}} = \hat{y}-y$
    
    The second part is dependent on the classifier that we use. 
    In case we use logistic regression $\hat{y} = \sigma(x \Theta + b)$, the expression becomes
    $\frac{\partial c(x)}{\partial x} = \hat{y} (1-\hat{y}) \Theta$
    Note, that it is easy to compute this expression even for more complicated classifiers. 
    Some libraries can even compute this automatically \cite{tensorflow2015-whitepaper}.
    However we still need that the classifier is differentiable, so we can not easily use SVM. 
    
    The third and last part is tied to the computation of LSA embedding.
    Because $x = d \circ w' U$, we can compute 
    $\frac{\partial x}{\partial d} = d U$ \* % TODO fix this math stuff
    
    Once we know how to computed the gradient, we need to decide on the the optimization routine we employ.

    \subsection{Optimization routine}
    
    We want to perform the gradient step $w' = w' - \frac{\partial E_y(\hat{y})}{\partial w'}$. 
    However this changes the input to the SVD and we should recompute the decomposition as well. 
    However it is not clear, how often we want to recompute the SVD and how often (and how much) we want to retrain the classifier.
    We propose two main approaches inspired by neural network training and by 
    expectation minimization algorithm. \* % TODO cite something
    
    Our model can be broken down into three parts: weighting, decomposition and classification.
    We will denote the weighting part as $W$, the decomposition part as $S$ (SVD) and the classification part as $C$.
    Also as these parts are going to be updated through the time, we will denote them with superscripts $W^t$, referring to weighting part $W$ at time $t$.
    
    
    \subsubsection{Batch gradient descent}
    
    We need to find the best weights $w'$ for the part $W$, 
    such that the decomposition $S$ captures the most information and hence the classifier $C$ has access to all the important features of the document.
    
    However, the decomposition $S$ is dependent on the reweighted matrix produced by $W$. 
    Because of this, after each update of $w'$ we need to fully recompute the decomposition $S$ and retrain the classifier $C$.
    The first optimization routine is described in algorithm \ref{algo:batch}.
    
    \medskip
    
    \begin{algorithm}[H]
        \KwData{$M$}
        \KwResult{trained $W$, $S$, $C$ }
        $w'^0 = 1$, $t=1$\;
        \While{not converged, $t$++}{
            recompute $S^t$ from $M \circ w'^{t-1}$\;
            compute embeddings $v^t$ from $M \circ w'^{t-1}$ with $S^t$\;
            fully train $C^t$ on $v^t$ and labels $y$\;
            updat $W^t$: $w'^t = w'^{t-1} - \alpha \frac{\partial E(C(S(M w'^{t-1}))}{\partial w'^{t-1}} $\;
        }
        \caption{stochastic training of $w'$} \label{algo:batch}
    \end{algorithm}
    
    Furthermore, we can increase the number of gradient steps performed on $w'$ in each step of the while loop.
    
    We took inspiration from expectation maximization algorithm.  
    Note, that it is not essential in any way for the reader to know this algorithm for further reading.
    
    This algorithm needs to do a lot of computations for one update of the weights $w'$.
    We recall the same problem in neural networks was solved by stochastic gradient descent.
    We try to employ such solution as well.
    
    \subsubsection{Stochastic gradient descent}
    
    We take the inspiration from stochastic gradient descent for neural networks.
    Instead of computing the full gradient, we just compute the gradient related to one example $\frac{\partial E_{y_i}(\hat{y_i})}{\partial w'}$.
    Because the document vector $d_i$ is sparse, we will only update a few values from $w'$, hence we can easily update part $W$.
    
    Because we updated $w'$, the entry in matrix $M$ corresponding to the document $d_i$ changed.
    We know, that SVD can be build incrementally and that we can add new documents to the matrix $M$ \cite{brand2006fast}.
    We just use the adding routine and add the new representation $d_i \circ w'^{t}$ to the decomposition.
    Because we changed the reweighed document and the decomposition matrices,
    the embedding of this document also changed to 
    $x_i^{t} = v_i^{t} = d_i w'^{t} U^{t}$
    
    We update $C$ in the similar manner.
    We perform the stochastic gradient step for example $x_i^{t+1}$ and threat it as a new example in the dataset.
    
    \begin{algorithm}[H]
        \KwData{$M$}
        \KwResult{trained $W$, $S$, $C$ }
        $w'^0 = 1$, $t=1$\;
        compute $S^0$ on $M \circ w'^{0}$\;
        compute embeddings $v^0$ from $M \circ w'^{0}$ with $S^0$\;
        fully train $C^0$ on $v^0$ and labels $y$\;
        
        \While{not converged}{
            \For{document $d_i \in M$, $i++$, $t++$}{
                add $d_i$ to $S^{t-1}$ and get $S^t$\;
                compute embedding $v_i^{t}$ from $d_i \circ w'^{t-1}$ with $S^t$\;
                perform gradient step on $C^{t-1}$ with $v_i^t$ to get $C^t$\;
                update $W^t$, $w'^t = w'^{t-1} - \alpha \frac{\partial E(C(S(d_i \circ w'^{t-1}))}{\partial w'^{t-1}} $\;    
            }
        }
        \caption{Batch training of $w'$}
    \end{algorithm}
    
    \subsubsection{Code explanations}
    
    There is a few technical details that we need to discuss, 
    mainly, what exactly do we mean by training until convergence.
    Motivated by our experimental results and good practice from neural network training,
    we split our dataset into $3$ parts: train, validation and test.
    
    We use train set for gradient evaluations and overall training. 
    We use the validation set to keep track of our performance on unseen data and finally we report the performance on the test set, that was never seen by the model.
    
    Each time step $t$ we evaluate our loss $E_{valid}$ on the validation dataset.
    By convergence we mean, that the $E_{valid}$ stopped improving.
    In the final solution we track the mean of this errors in last few time steps.
    When this mean does not increase for long enough, we stop the training.

\section{Implementation}
    
    In this section we go through some implementation details and decisions.
    Whole thesis, including experiment evaluations, is implemented in Python3.
    For code, please refer to appendix A. %\ref{appendix:a}

    \subsection{Libraries} 

    While implementing our approach, we made use of multiple tools and libraries that deserves to be mentioned.

    \subsubsection{Scikit-learn}
    
    Scikit-learn (or sklearn) is a free machine learning library for Python programming language \cite{scikit-learn}.
    It features wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems.
    It is extensible and provides very nice and clean APIs \cite{sklearn_api}.
    
    In this thesis, we used it for multiple purposes.
    We used base classes for weighting schemes \texttt{TfidfTransformer}, \texttt{BaseEstimator}, \texttt{TransformerMixin}.
    We also use this library to generate training and test splits. 
    
    Lastly, we used scikits implementation of \texttt{LogisticRegression}.
    However, in our approach we need to compute a derivative of our classifiers. 
    This implementation does not provide an API for this computation and we had to use
    its internal variables \texttt{coef\_} and \texttt{intercept\_} that corresponds to the weights and bias of the classifier.
    
    \subsubsection{Gensim}
    
    Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python \cite{rehurek_lrec}. 
    It is efficient and hassle-free software to realize unsupervised semantic modelling from plain text \cite{bird2009natural}. % nlp in python 
    It is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms. 
    
    We made use of multiple tools from this library. 
    We used \texttt{Dictionary} object for vocabulary filtering and embedding into the BOW representation and we used its TF-IDF implementations.
    We also used its API to train word vectors. \* % TODO train word vectors 
    
    Most important for us was gensims implementation of the probabilistic algorithm for constructing approximate matrix decomposition \cite{halko2011finding}.
    This provides fast and easy to use incremental SVD decomposition.
    
    \subsubsection{Numpy}
    
    NumPy is a library for Python, adding support for large, multi-dimensional arrays and matrices \cite{oliphant2006guide}. % numpy
    We used this library for result evaluation and to implement our own logistic regression.
    
    \subsubsection{TensorFlow}
    
    TensorFlow is an open source software library for high performance numerical computation developed by Google Brain team \cite{tensorflow2015-whitepaper}. 
    It provides simple interface to matrix computations on GPUs and CPUs.
    
    One of the most important capabilities of this library is automatic differentiation.
    We can create symbolic expression representing the desired computation $\hat{y}=g(X\Theta)$ and this library can automatically compute the gradient $\frac{\partial \hat{y}}{\Theta}$.
    Because of this, TensorFlow is very popular among  machine learning researchers.
    
    In theory, we could (and we wanted to) implement our whole approach in TensorFlow.
    It even contains implementation of SVD, but not with all the properties that we require.
    
    \subsubsection{Other used tools}
    
    During the development of required code we worked in Jupyter Notebook. 
    It is an interactive environment the offers very easy prototyping and
    data visualization \cite{PER-GRA:2007}. %ipython
    
    For data visualization we used Matplotlib library \cite{hunter2007matplotlib}. %matplotlib 
    
    Finally for data manipulation and presentation we used Pandas \cite{mckinney2010data}. %pandas
    
    Last important mention belongs to Aysen Tatarinov, his blog and his repository \url{https://github.com/aysent/supervised-term-weighting} where he implemented a number of supervised weight schemes \cite{maas2011learning}.
    \* % TODO coppyright v kode
    
    \subsection{Code design} 
    
    \* %     Something about used objects, classifiers, SVD, experiments, Two appraches