\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}


% Chapter: Document classification
{\input{document_classification.tex}}


\chapter{Similar work}
    \section{LSI with class knowledge}
        \subsection{Supervised LSI}
            \cite{sun2004supervised} %supervised lsi, discriminative basis

        \subsection{Sprinkling}
            \cite{chakraborti2007supervised} % Sprinkling
        
        \subsection{Supervised weights} \label{sec:supervised:weights}
            \cite{wu2017balancing} % word weights, TODO read
            \cite{ji2013discriminative} % TF KLD
            \cite{deng2014study} % supervised weights
            \cite{lan2009supervised} % supervised weights for text categorization

    
    \section{SVD in neural networks}
        \subsection{SVD as structured layer} 
            \cite{ionescu2015training} % svd in neural networks

    
\chapter{Our approach}
    
    In this chapter we describe our motivations, the actual design of our approach and some implementation details.
    
    \section{Goals and motivation}
    
    \* %TODO introduce minimal amount of hyperparameters,
    \* %TODO be able to get some insight and interpretability out of the model,

    In LSA, the SVD will inevitably throw away some information. 
    This is due the dimensionality reduction that it performs.
    The problem is, that this information may be vital to the classification task. 
    It is clear, that we need to introduce some form of supervision, that happens before the SVD.
    
    This is done to some extend by the supervised word weights described in section \ref{sec:supervised:weights}. 
    However, we consider this supervision rather weak, as it only computes simple statistics over words and labels.
    
    We would like to incorporate some form of direct supervision, that can be affected by the actual performance of the discriminator.
    We think it can be achieved by training our own word weighting scheme. 
    
    Our goals are:
    \begin{itemize}
        \item Propose a novel approach for learning task-specific word weights.
        \item Experimentally evaluate the performance of the new approach.
        \item Compare the new approach with other (commonly used) weighting schemes. 
        \item Extract new insights about the dataset.
    \end{itemize}
    
    Because of the supervised weights, we know that supervision helps. 
    The only problem is, how to achieve it. 
    Here we take the inspiration from neural networks, and the insight that we can easily optimize parameters of rather complex system, as long as each part of this system is differentiable. 
    
    \section{Design}
    
    First recall how does the original LSA works in context of document classification.
    We start with a sentence $s_i$. We represent it as a bag of words vector $d_i'$. 
    With some weighting scheme we transform it into a term vector $d_i$.
    Afterwards we compute the lower dimensional embedding of the document $v_i = d_i U$. 
    
    Finally we use these embeddings $v_i$ as features $x_i$ that are an input to the classifier (logistic regression, neural network, SVM).
    This classifier predicts some labels $\hat{y}$ that can be compared to
    the true labels $y$.
    
    Our contribution is to introduce another layer of reweighting. 
    Instead of using the term vector $d_i$, we introduce weights $w'$ and use reweighted vector $d_i \circ w'$.
    Recall, that $\circ$ means Hadamard product (pointwise multiplication).
    This is equivalent to multiplying the vector $d_i$ by diagonal matrix with diagonal $w'$.
    
    Further we do not perform the SVD decomposition on the matrix $M$, 
    but on the reweighted version $M \circ w'$. 
    Here we employ a few conventions from popular linear algebra library NumPy \cite{oliphant2006guide}, 
    where such operation is automatically broadcasted through the matrix.
    
    We initialize the $w'$ to be a vector of ones. 
    This effectively does not change the matrix at first.
    Now we are interested, in finding the best $w'$. 
    
    Recall, that for fixed decomposition $M\circ w'= U\Sigma V^T$ and some classifier $C$ (like a neural network),
    we compute $\hat{y} = C(M \circ w' U)$.
    We want to optimize $w'$ to minimize some error $E_y(\hat{y})$.
    The only question is, how to do it.
    
    The natural choice is to employ the gradient descent algorithm. 
    However to use it, we need to be able to compute the gradient of error with regards to the weights $\frac{\partial E_y(\hat{y})}{\partial w'}$.
    
    \subsection{Gradient computation}
    
    To compute the gradient efficiently, we recall the back-propagation trick mentioned in section \ref{sec:backprop}.
    We can compute the derivation $\frac{\partial E_y(\hat{y})}{\partial w'}$ thanks to the chain rule
    
    \begin{align}
    \frac{\partial E_y(\hat{y})}{\partial w'} = \frac{\partial E_y(\hat{y})}{\partial \hat{y}} \frac{\partial c(x)}{\partial x} \frac{\partial x}{\partial d}
    \end{align}
    
    To compute the derivation $\frac{\partial E_y(\hat{y})}{\partial w'} = \frac{\partial E_y(\hat{y})}{\partial \hat{y}} \frac{\partial C(x)}{\partial x} \frac{\partial x}{\partial d}$ we realize,
    that each part of this expression is easy to calculate.
    
    The first part of this expression is a function dependent on the chosen error function. 
    For L2 error we get 
    $\frac{\partial E_y(\hat{y})}{\partial \hat{y}} = \frac{\partial \frac{1}{2}(\hat{y}-y)^2}{\partial \hat{y}} = \hat{y}-y$
    
    The second part is dependent on the classifier that we use. 
    In case we use logistic regression $\hat{y} = \sigma(x \Theta + b)$, the expression becomes
    $\frac{\partial c(x)}{\partial x} = \hat{y} (1-\hat{y}) \Theta$
    Note, that it is easy to compute this expression even for more complicated classifiers. 
    Some libraries can even compute this automatically \cite{tensorflow2015-whitepaper}.
    However we still need that the classifier is differentiable, so we can not easily use SVM. 
    
    The third and last part is tied to the computation of LSA embedding.
    Because $x = d \circ w' U$, we can compute 
    $\frac{\partial x}{\partial d} = d U$ \* % TODO fix this math stuff
    
    Once we know how to computed the gradient, we need to decide on the the optimization routine we employ.
    
    \subsection{Optimization routine}
    
    We want to perform the gradient step $w' = w' - \frac{\partial E_y(\hat{y})}{\partial w'}$. 
    However this changes the input to the SVD and we should recompute the decomposition as well. 
    However it is not clear, how often we want to recompute the SVD and how often (and how much) we want to retrain the classifier.
    We propose two main approaches inspired by neural network training and by 
    expectation minimization algorithm. \* % TODO cite something
    
    Our model can be broken down into three parts: weighting, decomposition and classification.
    We will denote the weighting part as $W$, the decomposition part as $S$ (SVD) and the classification part as $C$.
    Also as these parts are going to be updated through the time, we will denote them with superscripts $W^t$, referring to $W$ at time $t$.
    
    
    \subsubsection{Batch gradient descent}
    
    We need to find the best weights $w'$ for the part $W$, 
    such that the decomposition $S$ captures the most information and hence the classifier $C$ has access to all the important features of the document.
    
    However, the decomposition $S$ is dependent on the reweighted matrix produced by $W$. 
    Because of this, after each update of $w'$ we need to fully recompute the decomposition $S$ and retrain the classifier $C$.
    The first optimization routine is described in algorithm \ref{algo:batch}.
    
    \medskip
    
    \begin{algorithm}[H]
        \KwData{$M$}
        \KwResult{trained $W$, $S$, $C$ }
        $w'^0 = 1$, $t=1$\;
        \While{not converged, $t$++}{
            recompute $S^t$ from $M \circ w'^{t-1}$\;
            compute embeddings $v^t$ from $M \circ w'^{t-1}$ with $S^t$\;
            fully train $C^t$ on $v^t$ and labels $y$\;
            updat $W^t$: $w'^t = w'^{t-1} - \alpha \frac{\partial E(C(S(M w'^{t-1}))}{\partial w'^{t-1}} $\;
        }
        \caption{stochastic training of $w'$} \label{algo:batch}
    \end{algorithm}

    Furthermore, we can increase the number of gradient steps performed on $w'$ in each step of the while loop.
    
    We took inspiration from expectation maximization algorithm.  
    Note, that it is not essential in any way for the reader to know this algorithm for further reading.
    
    This algorithm needs to do a lot of computations for one update of the weights $w'$.
    We recall the same problem in neural networks was solved by stochastic gradient descent.
    We try to employ such solution as well.
    
    \subsubsection{Stochastic gradient descent}
    
    We take the inspiration from stochastic gradient descent for neural networks.
    Instead of computing the full gradient, we just compute the gradient related to one example $\frac{\partial E_{y_i}(\hat{y_i})}{\partial w'}$.
    Because the document vector $d_i$ is sparse, we will only update a few values from $w'$, hence we can easily update part $W$.

    Because we updated $w'$, the entry in matrix $M$ corresponding to the document $d_i$ changed.
    We know, that SVD can be build incrementally and that we can add new documents to the matrix $M$ \cite{brand2006fast}.
    We just use the adding routine and add the new representation $d_i \circ w'^{t}$ to the decomposition.
    Because we changed the reweighed document and the decomposition matrices,
    the embedding of this document also changed to 
    $x_i^{t} = v_i^{t} = d_i w'^{t} U^{t}$
    
    We update $C$ in the similar manner.
    We perform the stochastic gradient step for example $x_i^{t+1}$ and threat it as a new example in the dataset.
    
    \begin{algorithm}[H]
        \KwData{$M$}
        \KwResult{trained $W$, $S$, $C$ }
        $w'^0 = 1$, $t=1$\;
        compute $S^0$ on $M \circ w'^{0}$\;
        compute embeddings $v^0$ from $M \circ w'^{0}$ with $S^0$\;
        fully train $C^0$ on $v^0$ and labels $y$\;
        
        \While{not converged}{
            \For{document $d_i \in M$, $i++$, $t++$}{
                add $d_i$ to $S^{t-1}$ and get $S^t$\;
                compute embedding $v_i^{t}$ from $d_i \circ w'^{t-1}$ with $S^t$\;
                perform gradient step on $C^{t-1}$ with $v_i^t$ to get $C^t$\;
                update $W^t$, $w'^t = w'^{t-1} - \alpha \frac{\partial E(C(S(d_i \circ w'^{t-1}))}{\partial w'^{t-1}} $\;    
            }
        }
        \caption{Batch training of $w'$}
    \end{algorithm}

    \subsubsection{Pseudocode explenations}
    
    There is a few technical details that we need to discuss, 
    mainly, what exactly do we mean by training until convergence.
    Motivated by our experimental results and good practice from neural network training,
    we split our dataset into $3$ parts: train, validation and test.
    
    We use train set for gradient evaluations and overall training. 
    We use the validation set to keep track of our performance on unseen data and finally we report the performance on the test set, that was never seen by the model.
    
    Each time step $t$ we evaluate our loss $E_{valid}$ on the validation dataset.
    By convergence we mean, that the $E_{valid}$ stopped improving.
    In the final solution we track the mean of this errors in last $X$ \* % TODO find number
    time steps.
    When this mean does not increase for long enough, we stop the training.
    
    \section{Implementation}
        
        In this section we go through some implementation details and decisions.
        For code, please refer to chapter \ref{chap:appendixa}. \*% add link

        While implementing our approach, we made use of multiple tools and libraries that deserves to be mentioned.

        \subsubsection{Scikit-learn}
        
        Scikit-learn (or sklearn) is a free machine learning library for Python programming language \cite{scikit-learn}.
        It features wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems.
        It is extensible and provides very nice APIs \cite{sklearn_api}.
        
        In our implementation we used base classes for weighting schemes \texttt{TfidfTransformer}, \texttt{BaseEstimator}, \texttt{TransformerMixin}.
        
        We also use this library to generate training and test splits. 
        
        Lastly, we used scikit's implementation of \texttt{LogisticRegression}.
        However, in our approach we need to compute a derivative of our classifiers. 
        This implementation does not provide an API for this computation and we had to use
        its internal variables \texttt{coef\_} and \texttt{intercept\_} that corresponds to the weights and bias of the classifier.
        
        
        \subsubsection{Gensim}
        weights, LSA, dictionaries, text manipulation
        Used gensim LSA that uses fast approximate SVD decomposition that cne be modified by new documents,
        
        \cite{rehurek_lrec}
        \* % TODO Intro about gensim
        \* % TODO cite the fast lsa in gensim
        \* % TODO, cite other important objects we use (dictionaries, sparse corpus), weights, word2 vec implementation
        
        
        \subsection{Numpy}
        \cite{bird2009natural} % nlp in python
        \cite{oliphant2006guide} % numpy
        for classification part we tried multiple models, , 
        our own logistic regression thanks to numpy, multilayer eprceptron from sklearn
        mlp with numpy, 
         \* %TODO implement this

        \subsection{Tensorflow}
        mlp with tensorflow
        \* %TODO implement or delete
        \* % note about computing the gradient authomaticaly,
        \* % discuss not used because of fast svd is not there.
    
        \subsection{Other used tools}
        \cite{perez2007ipython} %ipython
        \* % experiments, evaluation and development
        \* % cite python
        \* %cit the blog i used
        \cite{hunter2007matplotlib} %matplotlib
        \cite{mckinney2010data} %pandas
        
        
        

\chapter{Experiments and evaluation}

    Performance
    
    Result analysis
    
    Weight analysis
    
    Transfer learning?

    \section{Classification datasets}
        \subsection{Datasets}
            \cite{conneau2017supervised} % datasets, benchmarks

    \section{Interpretability}
        \cite{ribeiro2016should} % explainability


